# logistic-regression-vs-Perceptron
Analogy between Logistic Regression and a Perceptron

The work simply demonstrates how Logistic Regression in linear classification and a Perceptron in deep learning performs the same task but in different ways. It discusses the learning rule, activation function, update magnitude, convergence and mathematics behind the classifiers and compares the results of classification w.r.t cross-entropy-loss. They are trained on a generated data and show how both learn the rules differently. 

Finally, the work explains that a Perceptron is a strict learner and goes for an all-or-nothing approach and ignores subtle learning cues. Whereas, logistic regression adjusts to the flaws and improves itself gradually in the process. 

It validates my skills Python in understanding of machine learning algorithms and the complexities involved in mathematical foundation of these algorithms
